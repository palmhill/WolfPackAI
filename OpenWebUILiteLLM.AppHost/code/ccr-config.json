{
  "APIKEY": "ccr-dev-key-2024",
  "API_TIMEOUT_MS": 600000,
  "HOST": "0.0.0.0",
  "PORT": 3456,
  "ENABLE_ROUTER": true,
  "ENABLE_SUBAGENT": true,
  "ENABLE_TOOL_FORCING": true,
  "ENABLE_LOGGING": true,
  "LOG_LEVEL": "info",
  "providers": [
    {
      "name": "litellm-internal",
      "api_base_url": "http://litellm:4000/v1",
      "api_key": "your-litellm-master-key",
      "models": [
        "claude-3-5-sonnet-20241022",
        "claude-3-haiku-20240307", 
        "gpt-4o",
        "gemini-2.0-flash-exp",
        "deepseek-chat"
      ],
      "transformers": ["Anthropic", "OpenAI"],
      "description": "LiteLLM internal routing for fallback and general AI tasks"
    },
    {
      "name": "deepseek",
      "api_base_url": "https://api.deepseek.com/v1",
      "api_key": "${DEEPSEEK_API_KEY}",
      "models": [
        "deepseek-chat",
        "deepseek-coder",
        "deepseek-reasoner"
      ],
      "transformers": ["deepseek", "maxtoken"],
      "description": "DeepSeek models for cost-effective coding and reasoning"
    },
    {
      "name": "ollama-local", 
      "api_base_url": "http://ollama:11434/v1",
      "api_key": "ollama",
      "models": [
        "qwen2.5-coder:latest",
        "codellama:7b-instruct",
        "llama3.1:8b"
      ],
      "transformers": ["OpenAI", "tooluse"],
      "description": "Local Ollama models for offline development"
    },
    {
      "name": "openrouter",
      "api_base_url": "https://openrouter.ai/api/v1",
      "api_key": "${OPENROUTER_API_KEY}",
      "models": [
        "anthropic/claude-3-5-sonnet",
        "google/gemini-2.0-flash-exp",
        "qwen/qwen-2.5-coder-32b-instruct"
      ],
      "transformers": ["Anthropic", "OpenAI"],
      "description": "OpenRouter for accessing premium models"
    }
  ],
  "router": {
    "default": "deepseek,deepseek-chat",
    "background": "ollama-local,qwen2.5-coder:latest",
    "think": "litellm-internal,claude-3-5-sonnet-20241022",
    "longContext": "litellm-internal,gemini-2.0-flash-exp", 
    "webSearch": "litellm-internal,gpt-4o",
    "coder": "deepseek,deepseek-coder",
    "reasoning": "deepseek,deepseek-reasoner",
    "fallback": "litellm-internal,claude-3-haiku-20240307"
  },
  "agents": {
    "router": {
      "provider": "ollama-local",
      "model": "qwen2.5-coder:latest",
      "temperature": 0.1,
      "max_tokens": 1024
    },
    "tool": {
      "provider": "deepseek", 
      "model": "deepseek-coder",
      "temperature": 0.1,
      "max_tokens": 4096
    },
    "coder": {
      "provider": "deepseek",
      "model": "deepseek-coder", 
      "temperature": 0.2,
      "max_tokens": 8192
    },
    "think": {
      "provider": "litellm-internal",
      "model": "claude-3-5-sonnet-20241022",
      "temperature": 0.3,
      "max_tokens": 4096
    }
  },
  "thresholds": {
    "longContextThreshold": 8000,
    "complexityThreshold": 5,
    "toolCallThreshold": 3
  },
  "transformers": {
    "enableToolForcing": true,
    "maxTokens": 4096,
    "temperature": 0.1,
    "enableFallback": true,
    "retryAttempts": 3,
    "retryDelay": 1000
  },
  "security": {
    "allowedOrigins": ["http://localhost:5000", "http://localhost:3456"],
    "enableCORS": true,
    "rateLimitRequests": 100,
    "rateLimitWindow": 60000
  },
  "ui": {
    "enabled": true,
    "theme": "dark",
    "showAdvanced": true,
    "autoRefresh": true
  }
}